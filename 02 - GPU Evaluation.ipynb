{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0475860-ff11-4ec8-b0d6-6d7b20f3c36f",
   "metadata": {},
   "source": [
    "This notebook inspects the NVIDIA graphics capabilities of the system and detemines how much memory is available for models. The other notebooks assume that the system has at least 10 GB of GPU memory (vRAM). If your system has more or less that this amount, you can either choose different sized models (e.g. use flan-t5-large instead of flan-t5-xlarge) or adjust model quantization (e.g. use 8-bit model weights).\n",
    "\n",
    "You can determine the vRAM requirements of specific models, with or without varying levels quantization, at:\n",
    "https://huggingface.co/docs/accelerate/main/en/usage_guides/model_size_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "423ea3d6-4866-4366-a9bd-2679d5cb690c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver version : 535.154.05\n",
      "device count : 1\n",
      "device 0 : NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import pynvml\n",
    "\n",
    "pynvml.nvmlInit()\n",
    "\n",
    "print(f'driver version : {pynvml.nvmlSystemGetDriverVersion()}')\n",
    "\n",
    "devices = pynvml.nvmlDeviceGetCount()\n",
    "print(f'device count : {devices}')\n",
    "      \n",
    "for i in range(devices):\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "    print(f'device {i} : {pynvml.nvmlDeviceGetName(handle)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e320b7-27ec-4fb5-b639-183a76b127f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total : 10240 MB\n",
      "free  : 9624 MB\n",
      "used  : 615 MB\n"
     ]
    }
   ],
   "source": [
    "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "\n",
    "print(f'total : {info.total // 1024 ** 2} MB')\n",
    "print(f'free  : {info.free // 1024 ** 2} MB')\n",
    "print(f'used  : {info.used // 1024 ** 2} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d40f4064-6c61-4017-ad04-7aec654f1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b9dbde-27b9-4ad9-8a99-f6383d5975af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ebff8-fc92-468d-8bff-bd89f4cdd4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
